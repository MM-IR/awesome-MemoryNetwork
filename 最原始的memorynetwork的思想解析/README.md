# 1. memory network
这个就是reason with **inference components** combined with a **long-term memory component**.

>这里就是use these jointly.

这个long-term memory可以被read以及written to.@使用这个4 prediction.

>long-term memory 就是一个dynamic knowledge base, 然后输出就是一个textual response.

## RNN不擅长这个memorization task，就是simple copying task of input source都比较困难。

## memory network之所以看起来牛逼
主要是因为它就像是一个图灵机版的机器学习模型，而之前的大部分机器学习模型都是函数式的。


